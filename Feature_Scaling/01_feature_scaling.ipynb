{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import  MinMaxScaler\n",
    "\n",
    "\n",
    "# # sample data\n",
    "# data = {'value':[10,20,30,40,50]}\n",
    "# # data = {'number':[10,20,30,40,50]}\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data using min max scaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# # df['value'] = scaler.fit_transform(df['value'].values.reshape(-1,1))\n",
    "# df['values'] = scaler.fit_transform(df[['value']])\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. # Stadard Scaler or Z-score normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import  StandardScaler\n",
    "\n",
    "# # sample data\n",
    "# data = {'value':[10,20,30,40,50]}\n",
    "# # data = {'number':[10,20,30,40,50]}\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data using stadard scaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# # df['value'] = scaler.fit_transform(df['value'].values.reshape(-1,1))\n",
    "# df['value'] = scaler.fit_transform(df[['value']])\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Roubust Scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import  RobustScaler\n",
    "\n",
    "# # sample data with outliers\n",
    "# data = {'awen_number':[10,20,30,1000,50]}\n",
    "# # data = {'number':[10,20,30,40,50]}\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Scale data using Robust scaler\n",
    "# scaler = RobustScaler()\n",
    "# # df['value'] = scaler.fit_transform(df['value'].values.reshape(-1,1))\n",
    "# df['awen_number_scaled'] = scaler.fit_transform(df[['awen_number']])\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Logrithmic scalling / Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'awen_numbers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'awen_numbers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jahirul_islam\\Desktop\\PythonForDataScience\\Feature_Scaling\\01_feature_scaling.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jahirul_islam/Desktop/PythonForDataScience/Feature_Scaling/01_feature_scaling.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Log Transform\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jahirul_islam/Desktop/PythonForDataScience/Feature_Scaling/01_feature_scaling.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mawen_number_log\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(df[\u001b[39m'\u001b[39m\u001b[39mawen_nubmers\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jahirul_islam/Desktop/PythonForDataScience/Feature_Scaling/01_feature_scaling.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mawen_number_log2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog2(df[\u001b[39m'\u001b[39;49m\u001b[39mawen_numbers\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jahirul_islam/Desktop/PythonForDataScience/Feature_Scaling/01_feature_scaling.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mawen_number_log10\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog10(df[\u001b[39m'\u001b[39m\u001b[39mawen_numbers\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jahirul_islam/Desktop/PythonForDataScience/Feature_Scaling/01_feature_scaling.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'awen_numbers'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# random data\n",
    "data1 = {'awen_nubmers': [10000,20000,30000,100000,50000]}\n",
    "df = pd.DataFrame(data1)\n",
    "\n",
    "# Log Transform\n",
    "df['awen_number_log'] = np.log(df['awen_nubmers'])\n",
    "df['awen_number_log2'] = np.log2(df['awen_numbers'])\n",
    "df['awen_number_log10'] = np.log10(df['awen_numbers'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `awen_numbers_log` for `x`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jahirul_islam\\Desktop\\PythonForDataScience\\Feature_Scaling\\01_feature_scaling.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jahirul_islam/Desktop/PythonForDataScience/Feature_Scaling/01_feature_scaling.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jahirul_islam/Desktop/PythonForDataScience/Feature_Scaling/01_feature_scaling.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sns\u001b[39m.\u001b[39;49mboxplot(df, x\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mawen_numbers_log\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\seaborn\\categorical.py:1582\u001b[0m, in \u001b[0;36mboxplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, dodge, width, gap, whis, linecolor, linewidth, fliersize, hue_norm, native_scale, log_scale, formatter, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1574\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mboxplot\u001b[39m(\n\u001b[0;32m   1575\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, hue_order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1576\u001b[0m     orient\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, saturation\u001b[39m=\u001b[39m\u001b[39m.75\u001b[39m, fill\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1579\u001b[0m     legend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m, ax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   1580\u001b[0m ):\n\u001b[1;32m-> 1582\u001b[0m     p \u001b[39m=\u001b[39m _CategoricalPlotter(\n\u001b[0;32m   1583\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m   1584\u001b[0m         variables\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, hue\u001b[39m=\u001b[39;49mhue),\n\u001b[0;32m   1585\u001b[0m         order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1586\u001b[0m         orient\u001b[39m=\u001b[39;49morient,\n\u001b[0;32m   1587\u001b[0m         color\u001b[39m=\u001b[39;49mcolor,\n\u001b[0;32m   1588\u001b[0m         legend\u001b[39m=\u001b[39;49mlegend,\n\u001b[0;32m   1589\u001b[0m     )\n\u001b[0;32m   1591\u001b[0m     \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m         ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca()\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\seaborn\\categorical.py:62\u001b[0m, in \u001b[0;36m_CategoricalPlotter.__init__\u001b[1;34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     53\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m     legend\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m ):\n\u001b[1;32m---> 62\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, variables\u001b[39m=\u001b[39;49mvariables)\n\u001b[0;32m     64\u001b[0m     \u001b[39m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[39m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[39m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_format \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwide\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m orient \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\seaborn\\_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[39m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[39m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_ordered \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m}  \u001b[39m# alt., used DefaultDict\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massign_variables(data, variables)\n\u001b[0;32m    636\u001b[0m \u001b[39m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[39m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[39mfor\u001b[39;00m var \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mhue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstyle\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\seaborn\\_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m     \u001b[39m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[39m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[0;32m    677\u001b[0m     \u001b[39m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlong\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     plot_data \u001b[39m=\u001b[39m PlotData(data, variables)\n\u001b[0;32m    680\u001b[0m     frame \u001b[39m=\u001b[39m plot_data\u001b[39m.\u001b[39mframe\n\u001b[0;32m    681\u001b[0m     names \u001b[39m=\u001b[39m plot_data\u001b[39m.\u001b[39mnames\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\seaborn\\_core\\data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     52\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     53\u001b[0m     data: DataSource,\n\u001b[0;32m     54\u001b[0m     variables: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, VariableSpec],\n\u001b[0;32m     55\u001b[0m ):\n\u001b[0;32m     57\u001b[0m     data \u001b[39m=\u001b[39m handle_data_source(data)\n\u001b[1;32m---> 58\u001b[0m     frame, names, ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_assign_variables(data, variables)\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe \u001b[39m=\u001b[39m frame\n\u001b[0;32m     61\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m names\n",
      "File \u001b[1;32mc:\\Users\\jahirul_islam\\miniconda3\\envs\\python_eda\\Lib\\site-packages\\seaborn\\_core\\data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m         err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAn entry with this name does not appear in `data`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 232\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m \n\u001b[0;32m    236\u001b[0m     \u001b[39m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \n\u001b[0;32m    238\u001b[0m     \u001b[39m# Ignore empty data structures\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(val, Sized) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(val) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `awen_numbers_log` for `x`. An entry with this name does not appear in `data`."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(df, x='awen_numbers_log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assignment: Study Feature scaling completely. It's really very important in data sceince"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
